{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "使用relu激活函式來訓練(-1~1)範圍內進行\"乘上-1\"的神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, losses, initializers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_logical_device_configuration(physical_gpus[0], [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(name, init=\"glorot_uniform\"):\n",
    "    input_1 = keras.Input(shape=(1, ))\n",
    "    hidden_1 = layers.Dense(1, activation='tanh', kernel_initializer=init)(input_1)\n",
    "    output_1 = layers.Dense(1, kernel_initializer=init)(hidden_1)\n",
    "    model = keras.Model(name=name, inputs=[input_1], outputs=[output_1])\n",
    "    model.summary()\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    # model.compile(optimizer=optimizers.Adam(0.001), loss=losses.MeanSquaredError())\n",
    "    print(model.get_weights())\n",
    "    # plot_model(model, show_shapes=True)\n",
    "    return model\n",
    "init_list = [\n",
    "    initializers.glorot_uniform(),\n",
    "    initializers.he_normal()\n",
    "]\n",
    "# for i, init in enumerate(init_list):\n",
    "#     build_model(f\"model_{i}\", init)\n",
    "def build_one_model(num):\n",
    "    return build_model(f\"model_{num}\", init_list[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(name, init=\"glorot_uniform\"):\n",
    "    input_1 = keras.Input(shape=(1, ))\n",
    "    hidden_1 = layers.Dense(1, kernel_initializer=init)(input_1)\n",
    "    output_1 = layers.Dense(1, kernel_initializer=init)(hidden_1)\n",
    "    model = keras.Model(name=name, inputs=[input_1], outputs=[output_1])\n",
    "    model.summary()\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    # model.compile(optimizer=optimizers.Adam(0.001), loss=losses.MeanSquaredError())\n",
    "    print(model.get_weights())\n",
    "    # plot_model(model, show_shapes=True)\n",
    "    return model\n",
    "init_list = [\n",
    "    initializers.glorot_uniform(),\n",
    "    initializers.he_normal()\n",
    "]\n",
    "# for i, init in enumerate(init_list):\n",
    "#     build_model(f\"model_{i}\", init)\n",
    "def build_one_model(num):\n",
    "    return build_model(f\"model_{num}\", init_list[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = keras.Input(shape=(1, ))\n",
    "output_1 = layers.Dense(1, activation='relu')(input_1)\n",
    "model = keras.Model(inputs=[input_1], outputs=[output_1])\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "# model.compile(optimizer=optimizers.Adam(0.001), loss=losses.MeanSquaredError())\n",
    "print(model.get_weights())\n",
    "# plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num = 1000\n",
    "x_train = np.random.rand(num) * 2 - 1\n",
    "y_train = x_train * -1\n",
    "x_val = np.random.rand(num) * 2 - 1\n",
    "y_val = x_val * -1\n",
    "plt.subplot(211)\n",
    "plt.plot(x_train[:30], color='r', label='x_val')\n",
    "plt.plot(y_train[:30], color='b', label='y_val')\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "plt.plot(x_val[:30], color='r', label='x_val')\n",
    "plt.plot(y_val[:30], color='b', label='y_val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_dir = 'models'\n",
    "callbacks = list()\n",
    "''' EarlyStopping '''\n",
    "callbacks.append(\n",
    "    keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    ")\n",
    "''' ModelCheckpoint '''\n",
    "# model_name = 'epoch_{epoch:03d}-val_loss_{val_loss:.3f}.hdf5'\n",
    "# filepath = os.path.join(model_dir, model_name)\n",
    "# callbacks.append(\n",
    "#     keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "# )\n",
    "''' TensorBoard '''\n",
    "# log_dir = os.path.join(model_dir, 'log')\n",
    "# callbacks.append(\n",
    "#     keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "# )\n",
    "''' trainParam '''\n",
    "batch_size = 640\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = build_model('0')\n",
    "trainHistory = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(model.get_weights())\n",
    "plt.plot(trainHistory.history['loss'], color='r', label='loss')\n",
    "plt.plot(trainHistory.history['val_loss'], color='b', label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num = 1000\n",
    "x_test = np.random.rand(num) * 2 - 1\n",
    "y_test = x_test * -1\n",
    "predicted = model.predict(x_test)\n",
    "plt.plot(y_test[:30], color='r', label='y_test')\n",
    "plt.plot(predicted[:30], color='b', label='predicted')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "for i in range(100):\n",
    "    print(f'{x_test[i]:6.3f}, {predicted[i, 0]:6.3f}, ads_diff = {predicted[i, 0] + x_test[i]:6.3f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a1af232b417dd52ac5e484eceb9b15881c591b30356e01b51a9e4e51b5e3b8d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
