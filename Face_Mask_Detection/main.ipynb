{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.chdir(\"/home/jovyan/work/Face_Mask_Detection\")\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, losses, initializers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import utils\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kk693\\Desktop\\Git-Repository\\Tensorflow-Learning\\Face_Mask_Detection\\main.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kk693/Desktop/Git-Repository/Tensorflow-Learning/Face_Mask_Detection/main.ipynb#ch0000002?line=0'>1</a>\u001b[0m physical_gpus \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kk693/Desktop/Git-Repository/Tensorflow-Learning/Face_Mask_Detection/main.ipynb#ch0000002?line=1'>2</a>\u001b[0m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mset_memory_growth(physical_gpus[\u001b[39m0\u001b[39;49m], \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (\"without_mask\", \"with_mask\", \"mask_weared_incorrect\")\n",
    "train_dir = \"dataset/train\"\n",
    "val_dir = \"dataset/valid\"\n",
    "test_dir = \"dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator詳細：https://zhuanlan.zhihu.com/p/30197320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "#                                    rotation_range=10,\n",
    "#                                    shear_range=0.2,\n",
    "#                                    zoom_range=0.2,\n",
    "#                                    horizontal_flip=True)\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size=100, class_mode=\"categorical\", target_size=(64, 64))\n",
    "validation_generator = val_datagen.flow_from_directory(val_dir, batch_size=20, class_mode=\"categorical\", target_size=(64, 64))\n",
    "\n",
    "train_num = 3260"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加載VGG19預訓練模型：https://blog.csdn.net/dcrmg/article/details/81178424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights=\"imagenet\", input_shape=(64, 64, 3), include_top=False)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "plot_model(base_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何去掉模型的全連接層：https://blog.csdn.net/qq_29462849/article/details/83010854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(2048, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    layers.Dense(1024, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    layers.Dense(512, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    # layers.Dropout(0.2),\n",
    "    layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "model.summary()\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"categorical_accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReduceLROnPlateau待測試：https://hackmd.io/@allen108108/SyCsOIkxB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = 'model_2'\n",
    "models_dir = 'models'\n",
    "model_dir = os.path.join(models_dir, model_tag)\n",
    "callbacks = []\n",
    "''' EarlyStopping '''\n",
    "callbacks.append(\n",
    "    keras.callbacks.EarlyStopping(monitor=\"loss\", patience=100, verbose=1, mode=\"auto\")\n",
    ")\n",
    "''' ModelCheckpoint '''\n",
    "model_name = 'model.h5'\n",
    "filepath = os.path.join(model_dir, model_name)\n",
    "callbacks.append(\n",
    "    keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    ")\n",
    "''' ModelCheckpoint '''\n",
    "model_name = 'epoch_{epoch:03d}-val_loss_{val_loss:.3f}.h5'\n",
    "filepath = os.path.join(model_dir, \"checkpoint\", model_name)\n",
    "callbacks.append(\n",
    "    keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    ")\n",
    "''' TensorBoard '''\n",
    "log_dir = os.path.join(models_dir, 'logs', model_tag)\n",
    "callbacks.append(\n",
    "  keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    ")\n",
    "''' trainParam '''\n",
    "batch_size = 1000\n",
    "epochs = 1000\n",
    "steps_per_epoch = int(train_num / batch_size)\n",
    "print(f'steps_per_epoch = {steps_per_epoch}')\n",
    "print(f'filepath = {filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHistory = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainHistory.history['loss'], color='r', label='loss')\n",
    "plt.plot(trainHistory.history['val_loss'], color='b', label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainHistory.history['categorical_accuracy'], color='r', label='categorical_accuracy')\n",
    "plt.plot(trainHistory.history['val_categorical_accuracy'], color='b', label='val_categorical_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(f\"models/{model_tag}/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, shuffle=False, batch_size=406, class_mode=\"categorical\", target_size=(64, 64))\n",
    "Y_test_classes = np.argmax(test_generator[0][1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, categorical_accuracy = best_model.evaluate(test_generator)\n",
    "print(f\"ACC = {categorical_accuracy * 100:.4f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = best_model.predict(test_generator)\n",
    "predicts_classes = np.argmax(predicts, 1)\n",
    "utils.plot_confusion_matrix(Y_test_classes, predicts_classes, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cls in enumerate(labels):\n",
    "    print(f\"{i}. {cls}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a1af232b417dd52ac5e484eceb9b15881c591b30356e01b51a9e4e51b5e3b8d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
