{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### keras.datasets.mnist  (NumPy Array)\n",
    "(tra_im, tra_lb), (tes_im, tes_lb) = mnist.load_data()\n",
    "# 正規化\n",
    "tra_im_norm = tra_im / 255.0\n",
    "tes_im_norm = tes_im / 255.0\n",
    "# one-hot encoding\n",
    "tra_lb_onehot = utils.to_categorical(tra_lb)\n",
    "tes_lb_onehot = utils.to_categorical(tes_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分離訓練資料  -->  [0.8, 0.2] = [train, valid]\n",
    "split_idx = int(len(tra_im)*split)\n",
    "\n",
    "# training data\n",
    "tra_ds_im = Dataset.from_tensor_slices(tra_im_norm[:split_idx])    # 影像 Dataset\n",
    "tra_ds_lb = Dataset.from_tensor_slices(tra_lb_onehot[:split_idx])  # 標記 Dataset\n",
    "tra_ds = Dataset.zip((tra_ds_im, tra_ds_lb))  # 影像、標記整合成一個 Dataset\n",
    "tra_ds = tra_ds.batch(batch_size)  # 設定 Dataset 批次大小\n",
    "tra_ds = tra_ds.shuffle(split_idx) # 打亂 Dataset\n",
    "\n",
    "# validation data\n",
    "val_ds_im = Dataset.from_tensor_slices(tra_im_norm[split_idx:])    # 影像 Dataset\n",
    "val_ds_lb = Dataset.from_tensor_slices(tra_lb_onehot[split_idx:])  # 標記 Dataset\n",
    "val_ds = Dataset.zip((val_ds_im, val_ds_lb))  # 影像、標記整合成一個 Dataset\n",
    "val_ds = val_ds.batch(batch_size)  # 設定 Dataset 批次大小\n",
    "val_ds = val_ds.shuffle(len(tra_im)-split_idx) # 打亂 Dataset\n",
    "\n",
    "# testing data\n",
    "tes_ds_im = Dataset.from_tensor_slices(tes_im_norm)    # 影像 Dataset\n",
    "tes_ds_lb = Dataset.from_tensor_slices(tes_lb_onehot)  # 標記 Dataset\n",
    "tes_ds = Dataset.zip((tes_ds_im, tes_ds_lb))  # 影像、標記整合成一個 Dataset\n",
    "tes_ds = tes_ds.batch(batch_size)  # 設定 Dataset 批次大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_h(x):\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x\n",
    "def flip_v(x):\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    return x\n",
    "def rotate(x):\n",
    "    k = tf.random.uniform([], 1, 4, tf.int32)\n",
    "    x = tf.image.rot90(x, k)\n",
    "    return x\n",
    "def hue(x, val=0.08):  # 色調\n",
    "    x = tf.image.random_hue(x, val)\n",
    "    return x\n",
    "def brightness(x, val=0.05):  # 亮度\n",
    "    x = tf.image.random_brightness(x, val)\n",
    "    return x\n",
    "def saturation(x, minval=0.6, maxval=1.6):  # 飽和度\n",
    "    x = tf.image.random_saturation(x, minval, maxval)\n",
    "    return x\n",
    "def contrast(x, minval=0.7, maxval=1.3):  # 對比度\n",
    "    x = tf.image.random_contrast(x, minval, maxval)\n",
    "    return x\n",
    "def zoom(x, scale_minval=0.5, scale_maxval=1.5):\n",
    "    height, width, channel = x.shape\n",
    "    scale = tf.random.uniform([], scale_minval, scale_maxval)\n",
    "    new_size = (scale*height, scale*width)\n",
    "    x = tf.image.resize(x, new_size)\n",
    "    x = tf.image.resize_with_crop_or_pad(x, height, width)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fn(dataset, **kwargs):\n",
    "    if kwargs:\n",
    "        print(\"Data Augmentation!!!\")\n",
    "        for k, v in kwargs.items():\n",
    "            print(\"%15s:\"%k, v)\n",
    "    else:\n",
    "        print(\"Not Data Augmentation!!!\")\n",
    "    print()\n",
    "\n",
    "    # 分離 dataset\n",
    "    x = dataset[\"image\"]\n",
    "    y = dataset[\"label\"]\n",
    "\n",
    "    # 對影像進行正規化，及增加影像通道\n",
    "    # 因為 MNIST 是灰階影像，所以要自行加上通道，也就是第三軸\n",
    "    # 從 sahpe 來看就是變成 (28, 28)  ==>  (28, 28, 1)\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "\n",
    "    # 從 kwargs 來判斷哪些擴增需要執行\n",
    "    if kwargs.get(\"flip_h\", None):\n",
    "        x = tf.cond(tf.random.uniform((), 0, 1) > 0.5,\n",
    "                    lambda: flip_h(x), lambda: x)\n",
    "    if kwargs.get(\"flip_v\", None):\n",
    "        x = tf.cond(tf.random.uniform((), 0, 1) > 0.5,\n",
    "                    lambda: flip_v(x), lambda: x)\n",
    "    if kwargs.get(\"rotate\", None):\n",
    "        x = tf.cond(tf.random.uniform((), 0, 1) > 0.5,\n",
    "                    lambda: rotate(x), lambda: x)\n",
    "    if kwargs.get(\"hue\", None):\n",
    "        x = tf.cond(tf.random.uniform((), 0, 1) > 0.5,\n",
    "                    lambda: hue(x), lambda: x)\n",
    "    if kwargs.get(\"brightness\", None):\n",
    "        x = tf.cond(tf.random.uniform((), 0, 1) > 0.5,\n",
    "                    lambda: brightness(x), lambda: x)\n",
    "    if kwargs.get(\"saturation\", None):\n",
    "        x = tf.cond(tf.random.uniform((), 0, 1) > 0.5,\n",
    "                    lambda: saturation(x), lambda: x)\n",
    "    if kwargs.get(\"contrast\", None):\n",
    "        x = tf.cond(tf.random.uniform((), 0, 1) > 0.5,\n",
    "                    lambda: contrast(x), lambda: x)\n",
    "    if kwargs.get(\"zoom_scale\", None):\n",
    "        x = tf.cond(tf.random.uniform((), 0, 1) > 0.5,\n",
    "                    lambda: zoom(x), lambda: x)\n",
    "\n",
    "    # 對標記進行 one-hot encoding\n",
    "    y = tf.one_hot(y, 10)\n",
    "    return {\"image\": x}, {\"label\": y} # 回傳資料 (個人喜歡採用 dict 形式)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "split = 0.8\n",
    "augdict = {\n",
    "    # \"flip_h\": True,\n",
    "    # \"flip_v\": True,\n",
    "    # \"rotate\": True,\n",
    "    \"hue\": False,\n",
    "    \"saturation\": False,\n",
    "    \"contrast\": True,\n",
    "    \"brightness\": True,\n",
    "    \"zoom_scale\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "#-----------------------------------------------------------------------------#\n",
    "split_idx = int(len(X_train) * split)\n",
    "train_data = {\"image\": X_train[:split_idx], \"label\": Y_train[:split_idx]}\n",
    "val_data = {\"image\": X_train[split_idx:], \"label\": Y_train[split_idx:]}\n",
    "test_data = {\"image\": X_test, \"label\": Y_test}\n",
    "#-----------------------------------------------------------------------------#\n",
    "train_datasets = Dataset.from_tensor_slices(train_data)\n",
    "val_datasets = Dataset.from_tensor_slices(val_data)\n",
    "test_datasets = Dataset.from_tensor_slices(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('hue', False), ('saturation', False), ('contrast', True), ('brightness', True), ('zoom_scale', False)])\n",
      "Data Augmentation!!!\n",
      "            hue: False\n",
      "     saturation: False\n",
      "       contrast: True\n",
      "     brightness: True\n",
      "     zoom_scale: False\n",
      "\n",
      "dict_items([('hue', False), ('saturation', False), ('contrast', True), ('brightness', True), ('zoom_scale', False)])\n",
      "Data Augmentation!!!\n",
      "            hue: False\n",
      "     saturation: False\n",
      "       contrast: True\n",
      "     brightness: True\n",
      "     zoom_scale: False\n",
      "\n",
      "dict_items([])\n",
      "Not Data Augmentation!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "#-----------------------------------------------------------------------------#\n",
    "train_datasets = train_datasets.map(lambda ds: parse_fn(ds, **augdict), num_parallel_calls=autotune)\n",
    "train_datasets = train_datasets.shuffle(1000).batch(batch_size)\n",
    "#-----------------------------------------------------------------------------#\n",
    "val_datasets = val_datasets.map(lambda ds: parse_fn(ds, **augdict), num_parallel_calls=autotune)\n",
    "val_datasets = val_datasets.shuffle(1000).batch(batch_size)\n",
    "#-----------------------------------------------------------------------------#\n",
    "test_datasets = test_datasets.map(parse_fn, num_parallel_calls=autotune)\n",
    "test_datasets = test_datasets.batch(batch_size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a1af232b417dd52ac5e484eceb9b15881c591b30356e01b51a9e4e51b5e3b8d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
